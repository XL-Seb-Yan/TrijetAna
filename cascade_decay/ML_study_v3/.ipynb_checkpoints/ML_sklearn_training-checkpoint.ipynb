{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.22/06\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import ROOT\n",
    "from ROOT import TFile, TTree, TH1F, TCanvas, TAxis, TLegend, TTreeReader, TTreeReaderValue\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inFile = TFile(\"/home/xyan13/Trijet/TrijetAna/TrijetAna/outputs/Res1ToRes2GluTo3Glu_M1-3000_R-0p5_ML_study.root\")\n",
    "# inTree = inFile.Get(\"Events\")\n",
    "# variable2use = [i.GetName() for i in inTree.GetListOfBranches()]\n",
    "# display(variable2use)\n",
    "# for branch in variable2use:\n",
    "#     print(f\"{branch}[0] = event.{branch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(outTree):\n",
    "    data, columns = outTree.AsMatrix(return_labels=True)\n",
    "    df_temp = pd.DataFrame(data=data, columns=columns)\n",
    "    df = df_temp.iloc[:, :len(df_temp.columns)-1]\n",
    "    label = df_temp.iloc[:, len(df_temp.columns)-1:len(df_temp.columns)]\n",
    "    return df, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classification(df, label, model):\n",
    "    # Manually calculate classificiation efficiency\n",
    "    sig_index_list = np.where((label.values.ravel() == 1))[0].tolist()\n",
    "    N_test = len(sig_index_list)\n",
    "    clf_results_sig = np.array([])\n",
    "    N_correct = 0\n",
    "    N_tested = 0\n",
    "    # for i in range((df.shape)[0]): # Test both sig and bkg\n",
    "    #     index = i\n",
    "    for i, index in enumerate(sig_index_list): # Test sig only\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Reading: {i} out of {N_test}\")\n",
    "        is_correct = (label.values[index] == clf.predict(df[index:index+1])[0]) # If u use StandardScaler() to scale the data, need... \n",
    "        #...to be df[index:index+1, :], otherwise df[index:index+1]\n",
    "        if is_correct:\n",
    "            clf_results_sig = np.append(clf_results_sig, 1)\n",
    "        else:\n",
    "            clf_results_sig = np.append(clf_results_sig, 0)\n",
    "        # save results and restart again to speed things up\n",
    "        if i % 1000 == 0:\n",
    "            N_correct += np.sum(clf_results_sig)\n",
    "            N_tested += np.size(clf_results_sig)\n",
    "            print(N_correct, N_tested)\n",
    "            clf_results_sig = np.array([])\n",
    "    # Save the results from last batch\n",
    "    N_correct += np.sum(clf_results_sig)\n",
    "    N_tested += np.size(clf_results_sig)\n",
    "    # Calculate classification efficiency\n",
    "    print(N_correct, N_tested, N_correct / N_tested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_regreesion(df, label, model):\n",
    "    # Plot BDT output\n",
    "    sig_index_list = np.where((label.values.ravel() == 1))[0].tolist()\n",
    "    bkg_index_list = np.where((label.values.ravel() == 0))[0].tolist()\n",
    "    print(\"Number of signals for testing: \", len(sig_index_list))\n",
    "    print(\"Number of backgrounds for testing: \", len(bkg_index_list))\n",
    "    result_sig = clf.predict(df.iloc[sig_index_list])\n",
    "    result_bkg = clf.predict(df.iloc[bkg_index_list])\n",
    "    max_sig_response = max(result_sig)\n",
    "    max_bkg_response = max(result_bkg)\n",
    "    max_response = max([max_sig_response, max_bkg_response])\n",
    "    # Manually calculate classificiation efficiency\n",
    "    sig_eff_list = []\n",
    "    bkg_rej_list = []\n",
    "    sig_purity_list = []\n",
    "    sensitivity_list = []\n",
    "    cut_list = []\n",
    "    cut_90eff = -1\n",
    "    for cut in np.linspace(0,1,101):\n",
    "        N_sig = len(sig_index_list)\n",
    "        N_bkg = len(bkg_index_list)\n",
    "        N_sig_pass = len([x for x in result_sig if x > cut])\n",
    "        N_bkg_pass = len([x for x in result_bkg if x > cut])\n",
    "        if(N_bkg_pass == 0 or (N_sig_pass + N_bkg_pass) == 0):\n",
    "            print(\"Dividing zero, end loop\")\n",
    "            break\n",
    "        cut_list.append(cut)\n",
    "        sig_eff_list.append(N_sig_pass / N_sig)\n",
    "        if abs((N_sig_pass / N_sig) - 0.9) < 0.02:\n",
    "            print(N_sig_pass / N_sig, cut_90eff)\n",
    "            cut_90eff = cut\n",
    "        bkg_rej_list.append(1 - N_bkg_pass / N_bkg)\n",
    "        sig_purity_list.append(N_sig_pass / (N_sig_pass + N_bkg_pass))\n",
    "        sensitivity_list.append(N_sig_pass / math.sqrt(N_bkg_pass))\n",
    "    fig = plt.figure()   \n",
    "    ax0 = fig.add_subplot(3,1,1)\n",
    "    plt.hist(result_sig,50, color='r', alpha=0.5, label=\"match\")\n",
    "    plt.hist(result_bkg,50, color='b', alpha=0.5, label=\"unmatch\")\n",
    "    ax0.set_ylabel(\"Events\")\n",
    "    ax0.set_xlabel(\"BDT response\")\n",
    "    ax0.set_xlim(-0.01,max_response+0.05)\n",
    "    handles, labels = ax0.get_legend_handles_labels()\n",
    "    ax0.legend(handles, labels)\n",
    "    ax1 = fig.add_subplot(3,1,2)\n",
    "    ax1.plot(cut_list, sig_eff_list, label=\"Signal efficiency\", color=\"red\")\n",
    "    ax1.plot(cut_list, bkg_rej_list, label=\"Background rejection\", color=\"blue\")\n",
    "    ax1.plot(cut_list, sig_purity_list, label=\"Signal purity\", color=\"green\") \n",
    "    ax1.set_ylabel(\"\")\n",
    "    ax1.set_xlabel(\"Cut on BDT\")\n",
    "    ax1.set_xlim(-0.01,max_response+0.05)\n",
    "    handles, labels = ax1.get_legend_handles_labels()\n",
    "    ax1.legend(handles, labels)\n",
    "    ax1.grid(True)\n",
    "    ax2 = fig.add_subplot(3,1,3)\n",
    "    ax2.plot(cut_list, sensitivity_list, label=r\"$S/\\sqrt{B}$\", color=\"black\")\n",
    "    ax2.set_ylabel(\"\")\n",
    "    ax2.set_xlabel(\"Cut on BDT\")\n",
    "    ax2.set_xlim(-0.01,max_response+0.05)\n",
    "    handles, labels = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(handles, labels)\n",
    "    ax2.grid(True)\n",
    "    fig.set_figheight(20)\n",
    "    fig.set_figwidth(12)\n",
    "    print(\"90% signal efficiency cut: \", cut_90eff)\n",
    "    print(\"Optimal cut on BDT: \", cut_list[sensitivity_list.index(max(sensitivity_list))])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19505 118990 118990\n",
      "Processing:  0\n",
      "Processing:  10000\n",
      "Processing:  20000\n",
      "Processing:  30000\n",
      "Processing:  40000\n",
      "Processing:  50000\n",
      "Processing:  60000\n",
      "Processing:  70000\n",
      "Processing:  80000\n",
      "Processing:  90000\n",
      "Processing:  100000\n",
      "Processing:  110000\n",
      "Processing:  120000\n",
      "Processing:  130000\n"
     ]
    }
   ],
   "source": [
    "sample = \"M1-3000_R-0p3\"\n",
    "tempFile = TFile(f\"{sample}_training.root\",\"RECREATE\")\n",
    "outTree = TTree()\n",
    "inFile = TFile(f\"/home/xyan13/Trijet/TrijetAna/TrijetAna/outputs_3_jets/Res1ToRes2GluTo3Glu_{sample}_ML_study.root\")\n",
    "inTree = inFile.Get(\"Events\")\n",
    "dijet_eta = np.empty((1), dtype=\"float32\")\n",
    "dijet_phi = np.empty((1), dtype=\"float32\")\n",
    "dR_jj = np.empty((1), dtype=\"float32\")\n",
    "dEta_jj = np.empty((1), dtype=\"float32\")\n",
    "dPhi_jj = np.empty((1), dtype=\"float32\")\n",
    "dR_j0j2 = np.empty((1), dtype=\"float32\")\n",
    "dEta_j0j2 = np.empty((1), dtype=\"float32\")\n",
    "dPhi_j0j2 = np.empty((1), dtype=\"float32\")\n",
    "dR_j1j2 = np.empty((1), dtype=\"float32\")\n",
    "dEta_j1j2 = np.empty((1), dtype=\"float32\")\n",
    "dPhi_j1j2 = np.empty((1), dtype=\"float32\")\n",
    "jet_eta_0 = np.empty((1), dtype=\"float32\")\n",
    "jet_phi_0 = np.empty((1), dtype=\"float32\")\n",
    "jet_ptoverm_0 = np.empty((1), dtype=\"float32\")\n",
    "jet_eta_1 = np.empty((1), dtype=\"float32\")\n",
    "jet_phi_1 = np.empty((1), dtype=\"float32\")\n",
    "jet_ptoverm_1 = np.empty((1), dtype=\"float32\")\n",
    "jet_eta_2 = np.empty((1), dtype=\"float32\")\n",
    "jet_phi_2 = np.empty((1), dtype=\"float32\")\n",
    "jet_ptoverm_2 = np.empty((1), dtype=\"float32\")\n",
    "dR_jj_j = np.empty((1), dtype=\"float32\")\n",
    "dEta_jj_j = np.empty((1), dtype=\"float32\")\n",
    "dPhi_jj_j = np.empty((1), dtype=\"float32\")\n",
    "jet_ptoverM_0 = np.empty((1), dtype=\"float32\")\n",
    "jet_ptoverM_1 = np.empty((1), dtype=\"float32\")\n",
    "jet_ptoverM_2 = np.empty((1), dtype=\"float32\")\n",
    "dijet_ptoverM = np.empty((1), dtype=\"float32\")\n",
    "gen_dijet_matched = np.empty((1), dtype=\"int32\")\n",
    "\n",
    "outTree.Branch(\"dijet_eta\", dijet_eta, \"dijet_eta/F\")\n",
    "outTree.Branch(\"dijet_phi\", dijet_phi, \"dijet_phi/F\")\n",
    "outTree.Branch(\"dR_jj\", dR_jj, \"dR_jj/F\")\n",
    "outTree.Branch(\"dEta_jj\", dEta_jj, \"dEta_jj/F\")\n",
    "outTree.Branch(\"dPhi_jj\", dPhi_jj, \"dPhi_jj/F\")\n",
    "outTree.Branch(\"dR_j0j2\", dR_jj, \"dR_j0j2/F\")\n",
    "outTree.Branch(\"dEta_j0j2\", dEta_jj, \"dEta_j0j2/F\")\n",
    "outTree.Branch(\"dPhi_j0j2\", dPhi_jj, \"dPhi_j0j2/F\")\n",
    "outTree.Branch(\"dR_j1j2\", dR_jj, \"dR_j1j2/F\")\n",
    "outTree.Branch(\"dEta_j1j2\", dEta_jj, \"dEta_j1j2/F\")\n",
    "outTree.Branch(\"dPhi_j1j2\", dPhi_jj, \"dPhi_j1j2/F\")\n",
    "outTree.Branch(\"jet_eta_0\", jet_eta_0, \"jet_eta_0/F\")\n",
    "outTree.Branch(\"jet_phi_0\", jet_phi_0, \"jet_phi_0/F\")\n",
    "outTree.Branch(\"jet_ptoverm_0\", jet_ptoverm_0, \"jet_ptoverm_0/F\")\n",
    "outTree.Branch(\"jet_eta_1\", jet_eta_1, \"jet_eta_1/F\")\n",
    "outTree.Branch(\"jet_phi_1\", jet_phi_1, \"jet_phi_1/F\")\n",
    "outTree.Branch(\"jet_ptoverm_1\", jet_ptoverm_1, \"jet_ptoverm_1/F\")\n",
    "outTree.Branch(\"jet_eta_2\", jet_eta_2, \"jet_eta_2/F\")\n",
    "outTree.Branch(\"jet_phi_2\", jet_phi_2, \"jet_phi_2/F\")\n",
    "outTree.Branch(\"jet_ptoverm_2\", jet_ptoverm_2, \"jet_ptoverm_2/F\")\n",
    "outTree.Branch(\"dR_jj_j\", dR_jj_j, \"dR_jj_j/F\")\n",
    "outTree.Branch(\"dEta_jj_j\", dEta_jj_j, \"dEta_jj_j/F\")\n",
    "outTree.Branch(\"dPhi_jj_j\", dPhi_jj_j, \"dPhi_jj_j/F\")\n",
    "outTree.Branch(\"jet_ptoverM_0\", jet_ptoverM_0, \"jet_ptoverM_0/F\")\n",
    "outTree.Branch(\"jet_ptoverM_1\", jet_ptoverM_1, \"jet_ptoverM_1/F\")\n",
    "outTree.Branch(\"jet_ptoverM_2\", jet_ptoverM_2, \"jet_ptoverM_2/F\")\n",
    "outTree.Branch(\"dijet_ptoverM\", dijet_ptoverM, \"dijet_ptoverM/F\")\n",
    "outTree.Branch(\"gen_dijet_matched\", gen_dijet_matched, \"gen_dijet_matched/I\")\n",
    "\n",
    "n_all = inTree.GetEntries()\n",
    "array_ismatch = inTree.AsMatrix(columns=[\"gen_dijet_matched\"])\n",
    "array_matched = np.where((array_ismatch.ravel() == 3))[0]\n",
    "n_matched = np.shape(array_matched)[0]\n",
    "array_unmatched = np.where((array_ismatch.ravel() != 3))[0]\n",
    "n_unmatched = np.shape(array_unmatched)[0]\n",
    "print(n_matched, n_unmatched, n_all - n_matched)\n",
    "ratio = n_matched / n_unmatched\n",
    "from ROOT import TRandom3\n",
    "rand_gen = TRandom3()\n",
    "count_unmatch = 0\n",
    "for i, event in enumerate(inTree):\n",
    "    if i%10000 == 0:\n",
    "        print(\"Processing: \",i)\n",
    "    if(event.gen_dijet_matched != 3):\n",
    "        random = rand_gen.Uniform(0,1)\n",
    "        if random > ratio: \n",
    "            continue\n",
    "        gen_dijet_matched[0] = 0\n",
    "    else:\n",
    "        gen_dijet_matched[0] = 1\n",
    "    dijet_eta[0] = event.dijet_eta\n",
    "    dijet_phi[0] = event.dijet_phi\n",
    "    dR_jj[0] = event.dR_jj\n",
    "    dEta_jj[0] = event.dEta_jj\n",
    "    dPhi_jj[0] = event.dPhi_jj\n",
    "    dR_j0j2[0] = event.dR_j0j2\n",
    "    dEta_j0j2[0] = event.dEta_j0j2\n",
    "    dPhi_j0j2[0] = event.dPhi_j0j2\n",
    "    dR_j1j2[0] = event.dR_j1j2\n",
    "    dEta_j1j2[0] = event.dEta_j1j2\n",
    "    dPhi_j1j2[0] = event.dPhi_j1j2\n",
    "    jet_eta_0[0] = event.jet_eta_0\n",
    "    jet_phi_0[0] = event.jet_phi_0\n",
    "    jet_ptoverm_0[0] = event.jet_ptoverm_0\n",
    "    jet_eta_1[0] = event.jet_eta_1\n",
    "    jet_phi_1[0] = event.jet_phi_1\n",
    "    jet_ptoverm_1[0] = event.jet_ptoverm_1\n",
    "    jet_eta_2[0] = event.jet_eta_2\n",
    "    jet_phi_2[0] = event.jet_phi_2\n",
    "    jet_ptoverm_2[0] = event.jet_ptoverm_2\n",
    "    dR_jj_j[0] = event.dR_jj_j\n",
    "    dEta_jj_j[0] = event.dEta_jj_j\n",
    "    dPhi_jj_j[0] = event.dPhi_jj_j\n",
    "    jet_ptoverM_0[0] = event.jet_ptoverM_0\n",
    "    jet_ptoverM_1[0] = event.jet_ptoverM_1\n",
    "    jet_ptoverM_2[0] = event.jet_ptoverM_2\n",
    "    dijet_ptoverM[0] = event.dijet_ptoverM\n",
    "    outTree.Fill()\n",
    "df_1 = pd.DataFrame()\n",
    "label_1 = pd.DataFrame()\n",
    "df_1, label_1 = make_df(outTree)\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(df_1, label_1, test_size=0.33, random_state=1, stratify=label_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is intended for the single traning\n",
    "df_train = X_train_1\n",
    "label_train = y_train_1\n",
    "df_test = X_test_1\n",
    "label_test = y_test_1\n",
    "display(df_train.head())\n",
    "display(label_train.head())\n",
    "label_arr = np.array(label_train.iloc[1:,:]).ravel()\n",
    "all_N = np.shape(label_arr)\n",
    "sig_N = np.shape(np.where(label_arr == 1))\n",
    "print(all_N, sig_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is intended for mix traning using two samples\n",
    "N2train = min(X_train_1.shape[0], X_train_2.shape[0])\n",
    "print(N2train)\n",
    "df_train = pd.concat([X_train_1.iloc[:N2train, :], X_train_2.iloc[:N2train, :]])\n",
    "label_train = pd.concat([y_train_1.iloc[:N2train, :], y_train_2.iloc[:N2train, :]])\n",
    "print(df_train.shape[0])\n",
    "N2test = min(X_test_1.shape[0], X_test_2.shape[0])\n",
    "print(N2test)\n",
    "df_test = pd.concat([X_test_1.iloc[:N2test, :], X_test_2.iloc[:N2test, :]])\n",
    "label_test = pd.concat([y_test_1.iloc[:N2test, :], y_test_2.iloc[:N2test, :]])\n",
    "print(df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This cell is intended for PCA analysis, can be run seperately from ML traning\n",
    "variables = [var for var in df_1.columns[:len(df_1.columns)]]\n",
    "print(variables)\n",
    "scaled_df = preprocessing.scale(df_1)\n",
    "pca = PCA(0.95)\n",
    "pca.fit(scaled_df)\n",
    "PCA_df = pca.transform(scaled_df)\n",
    "PCA_df = pd.DataFrame(data = PCA_df[:,:2],columns = [\"PC1\",\"PC2\"])\n",
    "PCA_df_final = pd.concat([PCA_df,label_1] ,axis = 1)\n",
    "display(PCA_df_final.head())\n",
    "# Calculate percentage variation\n",
    "per_var = np.round(pca.explained_variance_ratio_ * 100, decimals = 1)\n",
    "# Calculate loading scores, determine best variables of each PCs\n",
    "for i in range(0, len(per_var)):\n",
    "    loading_scores = pd.Series(pca.components_[i], index=variables)\n",
    "    loading_scores = loading_scores.abs().sort_values(ascending=False)\n",
    "    display(loading_scores[:3])\n",
    "labels = [\"PC\" + str(x) for x in range(1, len(per_var)+1)]\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(x=range(1, len(per_var)+1), height=per_var, tick_label=labels)\n",
    "plt.ylabel(\"% of explained variance\")\n",
    "plt.xlabel(\"PC\")\n",
    "plt.xticks(rotation=270)\n",
    "plt.show()\n",
    "# display(pca.components_)\n",
    "\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "targets = [0,1]\n",
    "colors = [\"b\",\"r\"]\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = PCA_df_final[\"gen_dijet_matched\"] == target\n",
    "    ax.scatter(PCA_df_final.loc[indicesToKeep, \"PC1\"],\n",
    "               PCA_df_final.loc[indicesToKeep, \"PC2\"],\n",
    "               c = color,\n",
    "               s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# clf = MLPClassifier(solver='adam',hidden_layer_sizes=(20,20),random_state=1)\n",
    "clf = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4),n_estimators=200, random_state=1)\n",
    "clf.fit(df_train, label_train.values.ravel())\n",
    "# Score the fit using the pure QCD or Signal data\n",
    "# X_test = scaler.transform(X_test)\n",
    "# print(clf.score(X_test,y_test.values.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eval_regreesion(df_test, label_test, clf)\n",
    "eval_regreesion(df_train, label_train, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(clf, 'BDT_model_1.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
